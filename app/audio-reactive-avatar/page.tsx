'use client';

import { useState, useRef, useEffect } from 'react';
import AudioReactiveAvatar from '@/components/avatar/AudioReactiveAvatar';

export default function AudioReactiveAvatarDemo() {
  const [isListening, setIsListening] = useState(false);
  const [isPlayingAudio, setIsPlayingAudio] = useState(false);
  const [currentPhoneme, setCurrentPhoneme] = useState('');
  const [audioLevel, setAudioLevel] = useState(0);
  
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const micStreamRef = useRef<MediaStream | null>(null);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);

  // éŸ³ç´ æ¤œå‡ºã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯éŸ³å£°èªè­˜APIã‚’ä½¿ç”¨ï¼‰
  const simulatePhonemeDetection = (audioLevel: number) => {
    const phonemes = ['ã‚', 'ã„', 'ã†', 'ãˆ', 'ãŠ', 'ã‚“'];
    if (audioLevel > 0.3) {
      const randomPhoneme = phonemes[Math.floor(Math.random() * phonemes.length)];
      setCurrentPhoneme(randomPhoneme);
    } else {
      setCurrentPhoneme('');
    }
  };

  // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®åˆæœŸåŒ–
  const initAudioContext = () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 256;
    }
  };

  // ãƒã‚¤ã‚¯å…¥åŠ›ã®é–‹å§‹
  const startMicrophone = async () => {
    try {
      initAudioContext();
      
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      micStreamRef.current = stream;
      
      const source = audioContextRef.current!.createMediaStreamSource(stream);
      source.connect(analyserRef.current!);
      
      setIsListening(true);
      
      // éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®ç›£è¦–
      const dataArray = new Uint8Array(analyserRef.current!.frequencyBinCount);
      const updateAudioLevel = () => {
        if (!isListening) return;
        
        analyserRef.current!.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((a, b) => a + b) / dataArray.length / 255;
        setAudioLevel(average);
        simulatePhonemeDetection(average);
        
        requestAnimationFrame(updateAudioLevel);
      };
      updateAudioLevel();
    } catch (error) {
      console.error('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', error);
      alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚');
    }
  };

  // ãƒã‚¤ã‚¯å…¥åŠ›ã®åœæ­¢
  const stopMicrophone = () => {
    if (micStreamRef.current) {
      micStreamRef.current.getTracks().forEach(track => track.stop());
      micStreamRef.current = null;
    }
    setIsListening(false);
    setCurrentPhoneme('');
    setAudioLevel(0);
  };

  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿ
  const playAudioFile = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    try {
      initAudioContext();
      
      const audioUrl = URL.createObjectURL(file);
      
      if (!audioElementRef.current) {
        audioElementRef.current = new Audio();
      }
      
      audioElementRef.current.src = audioUrl;
      
      const source = audioContextRef.current!.createMediaElementSource(audioElementRef.current);
      source.connect(analyserRef.current!);
      analyserRef.current!.connect(audioContextRef.current!.destination);
      
      audioElementRef.current.play();
      setIsPlayingAudio(true);
      
      // éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®ç›£è¦–
      const dataArray = new Uint8Array(analyserRef.current!.frequencyBinCount);
      const updateAudioLevel = () => {
        if (!audioElementRef.current || audioElementRef.current.paused) {
          setIsPlayingAudio(false);
          setCurrentPhoneme('');
          setAudioLevel(0);
          return;
        }
        
        analyserRef.current!.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((a, b) => a + b) / dataArray.length / 255;
        setAudioLevel(average);
        simulatePhonemeDetection(average);
        
        requestAnimationFrame(updateAudioLevel);
      };
      updateAudioLevel();
      
      audioElementRef.current.onended = () => {
        setIsPlayingAudio(false);
        setCurrentPhoneme('');
        setAudioLevel(0);
      };
    } catch (error) {
      console.error('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å†ç”Ÿã‚¨ãƒ©ãƒ¼:', error);
    }
  };

  // ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ã®å†ç”Ÿ
  const playSampleText = (text: string) => {
    if ('speechSynthesis' in window) {
      window.speechSynthesis.cancel();
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ja-JP';
      utterance.rate = 0.9;
      
      // Web Speech APIã®éŸ³å£°ã‚’AudioContextã«æ¥ç¶šã™ã‚‹ã“ã¨ã¯å›°é›£ãªãŸã‚ã€
      // ã“ã“ã§ã¯éŸ³ç´ ã‚’æ‰‹å‹•ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      const phonemeSequence = text.split('').map(char => {
        const mapping: { [key: string]: string } = {
          'ã“': 'ãŠ', 'ã‚“': 'ã‚“', 'ã«': 'ã„', 'ã¡': 'ã„', 'ã¯': 'ã‚',
          'ã‚': 'ã‚', 'ãŸ': 'ã‚', 'ã—': 'ã„', 'ã®': 'ãŠ', 'æ­¯': 'ã‚',
          'ãŒ': 'ã‚', 'ç—›': 'ã„', 'ã': 'ã†', 'ã¦': 'ãˆ'
        };
        return mapping[char] || 'ã‚';
      });
      
      let index = 0;
      const animatePhonemes = () => {
        if (index < phonemeSequence.length) {
          setCurrentPhoneme(phonemeSequence[index]);
          setAudioLevel(0.5 + Math.random() * 0.3);
          index++;
          setTimeout(animatePhonemes, 150);
        } else {
          setCurrentPhoneme('');
          setAudioLevel(0);
        }
      };
      
      utterance.onstart = () => {
        setIsPlayingAudio(true);
        animatePhonemes();
      };
      
      utterance.onend = () => {
        setIsPlayingAudio(false);
      };
      
      window.speechSynthesis.speak(utterance);
    }
  };

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      stopMicrophone();
      if (audioElementRef.current) {
        audioElementRef.current.pause();
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, []);

  return (
    <div className="min-h-screen bg-gray-900 text-white p-8">
      <div className="max-w-7xl mx-auto">
        <h1 className="text-4xl font-bold text-blue-400 mb-8">éŸ³å£°åå¿œå‹ã‚¢ãƒã‚¿ãƒ¼ãƒ‡ãƒ¢</h1>
        
        <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
          <div className="space-y-6">
            <div className="bg-gray-800 rounded-lg p-6">
              <h2 className="text-2xl text-blue-300 mb-4">éŸ³å£°å…¥åŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³</h2>
              
              <div className="space-y-4">
                {/* ãƒã‚¤ã‚¯å…¥åŠ› */}
                <div>
                  <h3 className="text-lg font-semibold mb-2">1. ãƒã‚¤ã‚¯å…¥åŠ›</h3>
                  <button
                    onClick={isListening ? stopMicrophone : startMicrophone}
                    className={`px-6 py-3 rounded-lg font-semibold transition-colors ${
                      isListening 
                        ? 'bg-red-600 hover:bg-red-700' 
                        : 'bg-blue-600 hover:bg-blue-700'
                    }`}
                  >
                    {isListening ? 'ğŸ¤ éŒ²éŸ³åœæ­¢' : 'ğŸ¤ ãƒã‚¤ã‚¯ã§è©±ã™'}
                  </button>
                </div>

                {/* éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« */}
                <div>
                  <h3 className="text-lg font-semibold mb-2">2. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«</h3>
                  <input
                    type="file"
                    accept="audio/*"
                    onChange={playAudioFile}
                    className="block w-full text-sm text-gray-400
                      file:mr-4 file:py-2 file:px-4
                      file:rounded-full file:border-0
                      file:text-sm file:font-semibold
                      file:bg-blue-600 file:text-white
                      hover:file:bg-blue-700"
                  />
                </div>

                {/* ã‚µãƒ³ãƒ—ãƒ«éŸ³å£° */}
                <div>
                  <h3 className="text-lg font-semibold mb-2">3. ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°</h3>
                  <div className="grid grid-cols-1 gap-2">
                    <button
                      onClick={() => playSampleText('ã“ã‚“ã«ã¡ã¯')}
                      className="px-4 py-2 bg-green-600 hover:bg-green-700 rounded transition-colors"
                    >
                      ã€Œã“ã‚“ã«ã¡ã¯ã€
                    </button>
                    <button
                      onClick={() => playSampleText('ã‚ãŸã—ã®æ­¯ãŒç—›ãã¦')}
                      className="px-4 py-2 bg-green-600 hover:bg-green-700 rounded transition-colors"
                    >
                      ã€Œã‚ãŸã—ã®æ­¯ãŒç—›ãã¦ã€
                    </button>
                    <button
                      onClick={() => playSampleText('ã‚ã„ã†ãˆãŠ')}
                      className="px-4 py-2 bg-green-600 hover:bg-green-700 rounded transition-colors"
                    >
                      ã€Œã‚ã„ã†ãˆãŠã€
                    </button>
                  </div>
                </div>
              </div>
            </div>

            {/* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º */}
            <div className="bg-gray-800 rounded-lg p-6">
              <h2 className="text-2xl text-blue-300 mb-4">ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹</h2>
              <div className="space-y-2">
                <div className="flex justify-between">
                  <span>éŸ³å£°å…¥åŠ›:</span>
                  <span className={isListening || isPlayingAudio ? 'text-green-400' : 'text-gray-400'}>
                    {isListening ? 'ãƒã‚¤ã‚¯å…¥åŠ›ä¸­' : isPlayingAudio ? 'éŸ³å£°å†ç”Ÿä¸­' : 'åœæ­¢'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span>éŸ³é‡ãƒ¬ãƒ™ãƒ«:</span>
                  <span className="text-yellow-400">{(audioLevel * 100).toFixed(0)}%</span>
                </div>
                <div className="flex justify-between">
                  <span>æ¤œå‡ºéŸ³ç´ :</span>
                  <span className="text-purple-400">{currentPhoneme || 'ãªã—'}</span>
                </div>
              </div>
              
              {/* éŸ³é‡ãƒãƒ¼ */}
              <div className="mt-4">
                <div className="w-full bg-gray-700 rounded-full h-4">
                  <div 
                    className="bg-gradient-to-r from-green-400 to-yellow-400 h-4 rounded-full transition-all duration-150"
                    style={{ width: `${audioLevel * 100}%` }}
                  />
                </div>
              </div>
            </div>

            {/* èª¬æ˜ */}
            <div className="bg-gray-800 rounded-lg p-6">
              <h2 className="text-2xl text-blue-300 mb-4">ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³èª¬æ˜</h2>
              <div className="space-y-2 text-sm">
                <div className="flex items-start gap-2">
                  <span className="text-green-400">âœ“</span>
                  <span>ã‚·ã‚§ã‚¤ãƒ—ã‚­ãƒ¼: éŸ³ç´ ã«å¿œã˜ã¦å£ã®å½¢ãŒå¤‰åŒ–</span>
                </div>
                <div className="flex items-start gap-2">
                  <span className="text-green-400">âœ“</span>
                  <span>é¡ãƒœãƒ¼ãƒ³: ä½å‘¨æ³¢æ•°ã«åå¿œã—ã¦é–‹é–‰</span>
                </div>
                <div className="flex items-start gap-2">
                  <span className="text-green-400">âœ“</span>
                  <span>é ­éƒ¨ãƒœãƒ¼ãƒ³: éŸ³é‡ã«å¿œã˜ã¦è‡ªç„¶ãªæºã‚Œ</span>
                </div>
                <div className="flex items-start gap-2">
                  <span className="text-green-400">âœ“</span>
                  <span>èƒ¸éƒ¨ãƒœãƒ¼ãƒ³: å‘¼å¸ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</span>
                </div>
              </div>
            </div>
          </div>

          {/* ã‚¢ãƒã‚¿ãƒ¼è¡¨ç¤º */}
          <div className="bg-gray-800 rounded-lg p-6 h-[600px]">
            <AudioReactiveAvatar
              audioAnalyser={analyserRef.current}
              isSpeaking={isListening || isPlayingAudio}
              currentPhoneme={currentPhoneme}
              showDebug={true}
            />
          </div>
        </div>
      </div>
    </div>
  );
}