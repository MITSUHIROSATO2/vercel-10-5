// çµ±ä¸€ã•ã‚ŒãŸéŸ³å£°å†ç”Ÿã¨ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚µãƒ¼ãƒ“ã‚¹
// ãƒ‡ãƒ¢ã¨æœ¬ç•ªã®ä¸¡æ–¹ã§ä½¿ç”¨å¯èƒ½

interface AudioPlaybackOptions {
  text: string;
  base64Audio: string;
  onProgress?: (currentChar: string, audioLevel: number) => void;
  onEnd?: () => void;
  enableRealTimeAnalysis?: boolean; // æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ã§ã®ã¿æœ‰åŠ¹
}

class AudioService {
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private isInitialized = false;

  // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®åˆæœŸåŒ–ï¼ˆæœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
  private initializeAudioContext(): void {
    if (this.isInitialized || this.audioContext) return;

    try {
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 256;
      this.analyser.smoothingTimeConstant = 0.8;
      this.isInitialized = true;
    } catch (error) {
      console.warn('AudioContext initialization failed:', error);
    }
  }

  // æ—¥æœ¬èªã®éŸ³ç´ ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©ï¼ˆã‚ˆã‚Šç²¾å¯†ãªéŸ³å£°ãƒ¬ãƒ™ãƒ«ç”Ÿæˆã®ãŸã‚ï¼‰
  private getPhonemeAudioLevel(char: string): number {
    const vowels = ['ã‚', 'ã„', 'ã†', 'ãˆ', 'ãŠ', 'ã‚¢', 'ã‚¤', 'ã‚¦', 'ã‚¨', 'ã‚ª', 'a', 'i', 'u', 'e', 'o'];
    const nasalConsonants = ['ã‚“', 'ãƒ³', 'n', 'm'];
    const plosiveConsonants = ['ã‹', 'ã', 'ã', 'ã‘', 'ã“', 'ãŒ', 'ã', 'ã', 'ã’', 'ã”', 
                                'ãŸ', 'ã¡', 'ã¤', 'ã¦', 'ã¨', 'ã ', 'ã¢', 'ã¥', 'ã§', 'ã©',
                                'ã±', 'ã´', 'ã·', 'ãº', 'ã½', 'ã°', 'ã³', 'ã¶', 'ã¹', 'ã¼'];
    const fricativeConsonants = ['ã•', 'ã—', 'ã™', 'ã›', 'ã', 'ã–', 'ã˜', 'ãš', 'ãœ', 'ã',
                                  'ã¯', 'ã²', 'ãµ', 'ã¸', 'ã»'];
    
    // æ¯éŸ³ã¯é«˜ã„éŸ³å£°ãƒ¬ãƒ™ãƒ«
    if (vowels.includes(char)) {
      return 0.5 + Math.random() * 0.3; // 0.5-0.8
    }
    // é¼»éŸ³ã¯ä¸­ç¨‹åº¦
    else if (nasalConsonants.includes(char)) {
      return 0.3 + Math.random() * 0.2; // 0.3-0.5
    }
    // ç ´è£‚éŸ³ã¯çŸ­ã„é«˜ã„ãƒ”ãƒ¼ã‚¯
    else if (plosiveConsonants.includes(char)) {
      return 0.6 + Math.random() * 0.3; // 0.6-0.9
    }
    // æ‘©æ“¦éŸ³ã¯ä½ã‚ã§æŒç¶š
    else if (fricativeConsonants.includes(char)) {
      return 0.2 + Math.random() * 0.2; // 0.2-0.4
    }
    // ãã®ä»–ï¼ˆå­éŸ³ãªã©ï¼‰
    else if (char !== 'ã€' && char !== 'ã€‚' && char !== ' ') {
      return 0.3 + Math.random() * 0.3; // 0.3-0.6
    }
    // å¥èª­ç‚¹ãƒ»ã‚¹ãƒšãƒ¼ã‚¹
    return 0;
  }

  // ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
  private simulateLipSync(
    text: string,
    duration: number,
    onProgress?: (currentChar: string, audioLevel: number) => void
  ): { start: () => void; stop: () => void } {
    let intervalId: NodeJS.Timeout | null = null;
    let animationFrameId: number | null = null;
    let charIndex = 0;
    const characters = text.split('');
    
    // å®Ÿéš›ã®ç™ºè©±é€Ÿåº¦ã«è¿‘ã¥ã‘ã‚‹ãŸã‚ã€æ–‡å­—ã”ã¨ã®æ™‚é–“ã‚’èª¿æ•´
    // æ—¥æœ¬èªã®å¹³å‡ç™ºè©±é€Ÿåº¦: ç´„5-7éŸ³ç¯€/ç§’
    const charDuration = Math.max(80, Math.min(200, duration / characters.length));
    let lastCharTime = Date.now();
    let currentChar = '';
    let targetAudioLevel = 0;
    let currentAudioLevel = 0;
    
    const start = () => {
      // æ–‡å­—ã®é€²è¡Œã‚’ç®¡ç†
      intervalId = setInterval(() => {
        if (charIndex < characters.length) {
          currentChar = characters[charIndex];
          targetAudioLevel = this.getPhonemeAudioLevel(currentChar);
          charIndex++;
        } else {
          // æ–‡ã®çµ‚ã‚ã‚Šã«é”ã—ãŸã‚‰åœæ­¢
          targetAudioLevel = 0;
          if (intervalId) {
            clearInterval(intervalId);
            intervalId = null;
          }
        }
      }, charDuration);
      
      // ã‚¹ãƒ ãƒ¼ã‚ºãªã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ›´æ–°
      const animate = () => {
        // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«é·ç§»
        const smoothingFactor = 0.15;
        currentAudioLevel += (targetAudioLevel - currentAudioLevel) * smoothingFactor;
        
        // è‡ªç„¶ãªå¤‰å‹•ã‚’è¿½åŠ 
        const naturalVariation = Math.sin(Date.now() / 50) * 0.05;
        const finalAudioLevel = Math.max(0, Math.min(1, currentAudioLevel + naturalVariation));
        
        if (onProgress) {
          onProgress(currentChar, finalAudioLevel);
        }
        
        if (intervalId || currentAudioLevel > 0.01) {
          animationFrameId = requestAnimationFrame(animate);
        }
      };
      
      animate();
    };

    const stop = () => {
      if (intervalId) {
        clearInterval(intervalId);
        intervalId = null;
      }
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
        animationFrameId = null;
      }
      if (onProgress) {
        onProgress('', 0);
      }
    };

    return { start, stop };
  }

  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°åˆ†æï¼ˆæ”¹è‰¯ç‰ˆ - ãƒ‡ãƒ¢ã¨æœ¬ç•ªã®ä¸¡æ–¹ã§ä½¿ç”¨å¯èƒ½ï¼‰
  private startRealTimeAnalysis(
    audio: HTMLAudioElement,
    text: string,
    onProgress?: (currentChar: string, audioLevel: number) => void,
    useWordMode: boolean = true
  ): void {
    if (!this.audioContext || !this.analyser || !onProgress) return;

    try {
      // MediaElementSourceã¯ä¸€åº¦ã ã‘ä½œæˆå¯èƒ½ãªã®ã§ã€æ—¢å­˜ã®ã‚‚ã®ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
      let source: MediaElementAudioSourceNode;
      
      // audioè¦ç´ ã«ã‚½ãƒ¼ã‚¹ãŒæ—¢ã«é–¢é€£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
      if (!(audio as any)._audioSource) {
        source = this.audioContext.createMediaElementSource(audio);
        (audio as any)._audioSource = source;
        source.connect(this.analyser);
        this.analyser.connect(this.audioContext.destination);
      }

      const dataArray = new Uint8Array(this.analyser.frequencyBinCount);
      
      // å¥èª­ç‚¹ã‚’ä¿æŒã—ãªãŒã‚‰åŒºåˆ‡ã‚Šæ–‡å­—ã¨ã—ã¦æ‰±ã†ï¼ˆæœ¬ç•ªã¨åŒã˜å‡¦ç†ï¼‰
      const cleanText = text.replace(/([ã€ã€‚ï¼ï¼Ÿ,!?])/g, ' $1 ');
      const words = cleanText.split(/\s+/).filter(word => word.length > 0);
      
      let wordIndex = 0;
      let currentWord = '';
      let lastProgress = 0;

      const updateAnalysis = () => {
        if (audio.paused || audio.ended) {
          onProgress('', 0);
          return;
        }

        // å‘¨æ³¢æ•°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        this.analyser!.getByteFrequencyData(dataArray);
        
        // ã‚ˆã‚Šç²¾å¯†ãªéŸ³å£°ãƒ¬ãƒ™ãƒ«è¨ˆç®—
        let sum = 0;
        let weightedSum = 0;
        let count = 0;
        
        for (let i = 0; i < dataArray.length; i++) {
          const freq = i * this.audioContext!.sampleRate / (2 * dataArray.length);
          
          // äººã®å£°ã®åŸºæœ¬å‘¨æ³¢æ•°ç¯„å›²ï¼ˆ80-250Hzï¼‰ã¨å€éŸ³ï¼ˆ250-4000Hzï¼‰
          if (freq >= 80 && freq <= 250) {
            // åŸºæœ¬å‘¨æ³¢æ•°å¸¯åŸŸï¼ˆæœ€é‡è¦ï¼‰
            weightedSum += dataArray[i] * 2.0;
            count++;
          } else if (freq > 250 && freq <= 1000) {
            // ç¬¬1ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆå¸¯åŸŸ
            weightedSum += dataArray[i] * 1.5;
            count++;
          } else if (freq > 1000 && freq <= 3000) {
            // ç¬¬2ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆå¸¯åŸŸ
            weightedSum += dataArray[i] * 1.2;
            count++;
          } else if (freq > 3000 && freq <= 4000) {
            // é«˜å‘¨æ³¢æ•°å¸¯åŸŸï¼ˆå­éŸ³ï¼‰
            weightedSum += dataArray[i] * 1.0;
            count++;
          } else {
            sum += dataArray[i] * 0.5;
            count++;
          }
        }
        
        const average = count > 0 ? (weightedSum + sum) / count : 0;
        const audioLevel = Math.min(1, average / 180); // ã‚ˆã‚Šé©åˆ‡ãªæ­£è¦åŒ–

        // éŸ³å£°ã®é€²è¡Œã«åŸºã¥ã„ã¦å˜èªã‚’æ›´æ–°
        const progress = audio.currentTime / audio.duration;
        
        if (!isNaN(progress) && progress !== lastProgress) {
          const targetWordIndex = Math.min(
            Math.floor(progress * words.length),
            words.length - 1
          );
          
          if (targetWordIndex !== wordIndex && targetWordIndex >= 0) {
            wordIndex = targetWordIndex;
            currentWord = words[wordIndex] || '';
          }
          
          // å˜èªå†…ã§ã®è©³ç´°ãªéŸ³ç¯€ä½ç½®ã‚’è¨ˆç®—ï¼ˆæœ¬ç•ªã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
          if (currentWord && useWordMode) {
            const wordStartProgress = wordIndex / words.length;
            const wordEndProgress = (wordIndex + 1) / words.length;
            const wordRelativeProgress = Math.max(0, Math.min(1, 
              (progress - wordStartProgress) / (wordEndProgress - wordStartProgress)
            ));
            
            // æ—¥æœ¬èªã®éŸ³ç¯€ï¼ˆãƒ¢ãƒ¼ãƒ©ï¼‰å˜ä½ã§å‡¦ç†
            const moraCount = currentWord.replace(/[ã‚ƒã‚…ã‚‡ãƒ£ãƒ¥ãƒ§]/g, '').length;
            const moraIndex = Math.min(
              Math.floor(wordRelativeProgress * moraCount), 
              moraCount - 1
            );
            
            // ç¾åœ¨ã®éŸ³ç¯€ã‚’å–å¾—
            let currentMora = '';
            let count = 0;
            for (let i = 0; i < currentWord.length; i++) {
              if (count === moraIndex) {
                currentMora = currentWord[i];
                // æ‹—éŸ³ã‚’ãƒã‚§ãƒƒã‚¯
                if (i + 1 < currentWord.length && 'ã‚ƒã‚…ã‚‡ãƒ£ãƒ¥ãƒ§'.includes(currentWord[i + 1])) {
                  currentMora += currentWord[i + 1];
                }
                break;
              }
              if (!'ã‚ƒã‚…ã‚‡ãƒ£ãƒ¥ãƒ§'.includes(currentWord[i])) {
                count++;
              }
            }
            
            // FinalLipSyncAvatarã«æ¸¡ã™æ–‡å­—
            onProgress(currentMora || currentWord[0] || '', audioLevel);
          } else {
            // å˜èªå…¨ä½“ã‚’æ¸¡ã™
            onProgress(currentWord, audioLevel);
          }
          
          lastProgress = progress;
        }

        requestAnimationFrame(updateAnalysis);
      };

      // å†ç”Ÿé–‹å§‹æ™‚ã«åˆ†æã‚’é–‹å§‹
      const playHandler = () => updateAnalysis();
      audio.addEventListener('play', playHandler, { once: true });
      
      // æ—¢ã«å†ç”Ÿä¸­ã®å ´åˆã¯ã™ãã«é–‹å§‹
      if (!audio.paused && !audio.ended) {
        updateAnalysis();
      }
    } catch (error) {
      console.warn('Real-time analysis setup failed:', error);
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’ä½¿ç”¨
      if (onProgress) {
        this.simulateLipSync(text, audio.duration * 1000, onProgress).start();
      }
    }
  }

  // çµ±ä¸€ã•ã‚ŒãŸéŸ³å£°å†ç”Ÿãƒ¡ã‚½ãƒƒãƒ‰
  async playAudio(options: AudioPlaybackOptions): Promise<void> {
    const { text, base64Audio, onProgress, onEnd, enableRealTimeAnalysis = false } = options;

    return new Promise((resolve, reject) => {
      try {
        // Base64ã‚’Blobã«å¤‰æ›
        const byteCharacters = atob(base64Audio);
        const byteArray = new Uint8Array(byteCharacters.length);
        for (let i = 0; i < byteCharacters.length; i++) {
          byteArray[i] = byteCharacters.charCodeAt(i);
        }
        const blob = new Blob([byteArray], { type: 'audio/mpeg' });
        const audioUrl = URL.createObjectURL(blob);
        
        const audio = new Audio(audioUrl);
        audio.preload = 'auto';
        audio.volume = 1.0;
        audio.crossOrigin = 'anonymous'; // CORSå¯¾å¿œ
        
        let lipSyncController: { start: () => void; stop: () => void } | null = null;

        // éŸ³å£°æº–å‚™å®Œäº†æ™‚ã®å‡¦ç†
        audio.addEventListener('canplaythrough', () => {
          // AudioContextã®åˆæœŸåŒ–ï¼ˆå…¨ãƒ¢ãƒ¼ãƒ‰ã§ä½¿ç”¨ã‚’è©¦ã¿ã‚‹ï¼‰
          this.initializeAudioContext();
          if (this.audioContext?.state === 'suspended') {
            this.audioContext.resume();
          }

          // å†ç”Ÿé–‹å§‹
          audio.play()
            .then(() => {
              console.log('ğŸ”Š Audio playback started');
              
              // ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚AudioContextã‚’è©¦ã¿ã‚‹
              if (this.audioContext && this.analyser) {
                // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã‚’è©¦ã¿ã‚‹ï¼ˆå˜èªãƒ¢ãƒ¼ãƒ‰ã§ï¼‰
                this.startRealTimeAnalysis(audio, text, onProgress, true);
              } else {
                // AudioContextãŒä½¿ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                const estimatedDuration = audio.duration * 1000 || 3000;
                lipSyncController = this.simulateLipSync(text, estimatedDuration, onProgress);
                lipSyncController.start();
              }
            })
            .catch((error) => {
              console.warn('Audio playback blocked:', error);
              URL.revokeObjectURL(audioUrl);
              resolve(); // ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶šè¡Œ
            });
        }, { once: true });

        // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        audio.onerror = (error) => {
          console.error('Audio loading error:', error);
          URL.revokeObjectURL(audioUrl);
          if (lipSyncController) lipSyncController.stop();
          reject(new Error('Audio loading failed'));
        };

        // å†ç”Ÿçµ‚äº†æ™‚
        audio.onended = () => {
          URL.revokeObjectURL(audioUrl);
          if (lipSyncController) lipSyncController.stop();
          if (onProgress) onProgress('', 0);
          if (onEnd) onEnd();
          resolve();
        };

        // éŸ³å£°ã®ãƒ­ãƒ¼ãƒ‰é–‹å§‹
        audio.load();
      } catch (error) {
        console.error('Audio processing error:', error);
        reject(error);
      }
    });
  }

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  cleanup(): void {
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    this.analyser = null;
    this.isInitialized = false;
  }
}

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const audioService = new AudioService();